{"cells":[{"metadata":{"_uuid":"bd72bc71-59c9-4931-834b-1d0063e86857","_cell_guid":"ec127fd9-e65c-4d8d-a1c4-ed38871d17b0","trusted":true},"cell_type":"code","source":"# %% [code]\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\"\"\"\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\"\"\"\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport librosa\nimport librosa.display\nimport glob\nimport os\nimport matplotlib.pyplot as plt\nfrom matplotlib import figure\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Dropout, Activation\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.utils import to_categorical\nfrom keras.models import model_from_json\n\n\n\n!mkdir /kaggle/working/train\n\n# convert audio files into pictures (spectrogram)\ndef create_spectrogram(file_name,name):\n    try:\n        plt.interactive(False)\n        clip, sample_rate = librosa.load(file_name, sr=None)\n        fig = plt.figure(figsize=[0.72,0.72])\n        ax = fig.add_subplot(111)\n        ax.axes.get_xaxis().set_visible(False)\n        ax.axes.get_yaxis().set_visible(False)\n        ax.set_frame_on(False)\n        S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n        librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n        file_name  = '/kaggle/working/train/' + name + '.jpg'\n        plt.savefig(file_name, dpi=400, bbox_inches='tight',pad_inches=0)\n        plt.close()    \n        fig.clf()\n        plt.close(fig)\n        plt.close('all')\n        del file_name, name, clip, sample_rate, fig, ax, S\n    except Exception as e:\n        print(\"Error encountered while parsing file: \", file_name)\n\n\n# generate image data from audio data\ndata_dir=np.array(glob.glob(\"../input/birdsong-recognition/train_audio/*/*.mp3\"))\n\n\nfor file in tqdm(data_dir):\n    filename, name = file, file.split('/')[-1].split('.')[0]\n    create_spectrogram(filename, name)\n\n\n\n# initialize image generator\ndef append_ext(fn):\n    return fn.split('.')[0] + \".jpg\"\n\ntraindf = pd.read_csv('../input/birdsong-recognition/train.csv',dtype = str)\ntraindf[\"filename\"] = traindf[\"filename\"].apply(append_ext)\n\ndatagen = ImageDataGenerator(rescale = 1./255., validation_split = 0.25)\n\ntrain_generator = datagen.flow_from_dataframe(\n    dataframe=traindf,\n    directory=\"/kaggle/working/train/\",\n    x_col=\"filename\",\n    y_col=\"species\",\n    subset=\"training\",\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"categorical\",\n    target_size=(64,64))\n\nnum_class = len(set(train_generator.classes))\n\n\nvalid_generator=datagen.flow_from_dataframe(\n    dataframe=traindf,\n    directory=\"/kaggle/working/train/\",\n    x_col=\"filename\",\n    y_col=\"species\",\n    subset=\"validation\",\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"categorical\",\n    target_size=(64,64))\n\n\n# build a CNN model for classification\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding='same',\n                 input_shape=(64,64,3)))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\nmodel.add(Conv2D(128, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(128, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_class, activation='softmax'))\n\nadam = Adam(lr=0.0005, decay=1e-6)\nmodel.compile(optimizer=adam, loss=\"categorical_crossentropy\" ,metrics=[\"accuracy\"])\nmodel.summary()\n\n# train the model\nSTEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n\nmodel.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=150)\nmodel.evaluate_generator(generator=valid_generator, steps=STEP_SIZE_VALID)\n\n# serialize model to JSON\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n\n# serialize weights to HDF5\nmodel.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")\n \n# later...\n \n# load json and create model\njson_file = open('model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n\n# load weights into new model\nloaded_model.load_weights(\"model.h5\")\nprint(\"Loaded model from disk\")\n\n\n\n# Reference: https://medium.com/gradientcrescent/urban-sound-classification-using-convolutional-neural-networks-with-keras-theory-and-486e92785df4","execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}