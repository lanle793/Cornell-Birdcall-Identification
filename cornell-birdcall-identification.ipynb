{"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\"\"\"\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\"\"\"\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport librosa\nimport glob\nimport pandas as pd\nimport os\nfrom keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Dropout\nfrom keras.optimizers import Adam\nfrom keras.models import model_from_json\n\n\n# TODO: Check number of input features\ndef get_mfcc_features(file_path):\n    try:\n        audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast') \n        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n        mfccsscaled = np.mean(mfccs.T,axis=0)\n    except Exception as e:\n        print(\"Error encountered while parsing file: \", file_path)\n        return None\n    \n    return mfccsscaled\n\n\n# try loading data\ndata_loaded = True\nX_train = None\ny_train = None\n\ntry:\n    X_train = np.load('../input/saved-input/X_train.npy')\n    y_train = np.load('../input/saved-input/y_train.npy')\n    print(\"Input loaded successfully\")\nexcept IOError:\n    print(\"Input data has not been saved\")\n    data_loaded = False\n\n\n# prepare input data\nbase_path = \"../input/birdsong-recognition\"\ntrain_audio_path = base_path + \"/train_audio\"\nfile1 = train_audio_path + \"/aldfly/XC134874.mp3\"\ntrain_audio_list = glob.glob(train_audio_path + '/*/*.mp3')\nprint(len(train_audio_list))\n\ntrain_csv = pd.read_csv(base_path + '/train.csv')\ntrain_csv.head()\n\nif not data_loaded:\n    labels = []\n    features = []\n\n    for path in tqdm(train_audio_list):\n        base_file = os.path.basename(path)\n        #feature = get_mfcc_features(path)\n        #if feature is None:\n            #continue\n        #features.append(feature)\n        label = train_csv.loc[train_csv.filename == base_file, 'ebird_code'].values[0]\n        labels.append(label)\n\n    X_train = np.array(features)\n    y_train = np.array(labels)\n    \n    encoder = LabelEncoder()\n    y_train = to_categorical(encoder.fit_transform(y_train))\n\n    # save generated data\n    np.save('X_train', X_train)\n    np.save('y_train', y_train)\n\nprint(X_train.shape)\nprint(y_train.shape)\nprint(y_train[:2, :])\n\n\n# build the model\nmodel = Sequential()\n\nmodel.add(Dense(1024, input_shape=(40,), activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(264, activation='softmax'))\n\n# Display model architecture summary \nmodel.summary()\n\nadam = Adam(lr=0.001)\n\nmodel.compile(loss='categorical_crossentropy',\n                  optimizer=adam,\n                  metrics=['accuracy'])\n\n# Calculate pre-training accuracy \nscore = model.evaluate(X_train, y_train, verbose=0)\naccuracy = 100*score[1]\n\nprint(\"Pre-training accuracy: %.4f%%\" % accuracy)\n\n# train the model\nhistory = model.fit(x=X_train, y=y_train, epochs=20, batch_size=32, shuffle=True)\n\n# serialize model to JSON\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n\n# serialize weights to HDF5\nmodel.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")\n \n# later...\n \n# load json and create model\njson_file = open('model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n\n# load weights into new model\nloaded_model.load_weights(\"model.h5\")\nprint(\"Loaded model from disk\")\n\n\n\n\n# Reference: https://medium.com/@mikesmales/sound-classification-using-deep-learning-8bc2aa1990b7","metadata":{"collapsed":false,"_kg_hide-input":false},"execution_count":0,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":4}