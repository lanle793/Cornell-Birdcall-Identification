{"cells":[{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\"\"\"\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\"\"\"\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport librosa\nimport librosa.display\nimport glob\nimport os\nimport matplotlib.pyplot as plt\nfrom matplotlib import figure\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Dropout, Activation\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.utils import to_categorical\nfrom keras.models import model_from_json\n\n\n\n!mkdir /kaggle/working/train\n\n# convert audio files into pictures (spectrogram)\ndef create_spectrogram(file_name,name):\n    try:\n        plt.interactive(False)\n        clip, sample_rate = librosa.load(file_name, sr=None)\n        fig = plt.figure(figsize=[0.72,0.72])\n        ax = fig.add_subplot(111)\n        ax.axes.get_xaxis().set_visible(False)\n        ax.axes.get_yaxis().set_visible(False)\n        ax.set_frame_on(False)\n        S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n        librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n        file_name  = '/kaggle/working/train/' + name + '.jpg'\n        plt.savefig(file_name, dpi=400, bbox_inches='tight',pad_inches=0)\n        plt.close()    \n        fig.clf()\n        plt.close(fig)\n        plt.close('all')\n        del file_name, name, clip, sample_rate, fig, ax, S\n    except Exception as e:\n        print(\"Error encountered while parsing file: \", file_name)\n\n\n# generate image data from audio data\ndata_dir=np.array(glob.glob(\"../input/birdsong-recognition/train_audio/*/*.mp3\"))\n\n\nfor file in tqdm(data_dir[0:2000]):\n    filename, name = file, file.split('/')[-1].split('.')[0]\n    create_spectrogram(filename, name)\n\n\n\n# initialize image generator\ndef append_ext(fn):\n    return fn.split('.')[0] + \".jpg\"\n\ntraindf = pd.read_csv('../input/birdsong-recognition/train.csv',dtype = str)\ntraindf[\"filename\"] = traindf[\"filename\"].apply(append_ext)\n\ndatagen = ImageDataGenerator(rescale = 1./255.) #, validation_split = 0.25)\n\ntrain_generator = datagen.flow_from_dataframe(\n    dataframe=traindf,\n    directory=\"/kaggle/working/train/\",\n    x_col=\"filename\",\n    y_col=\"species\",\n    subset=\"training\",\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"categorical\",\n    target_size=(64,64))\n\nnum_class = len(set(train_generator.classes))\n\n\"\"\"\nvalid_generator=datagen.flow_from_dataframe(\n    dataframe=traindf,\n    directory=\"/kaggle/working/train/\",\n    x_col=\"filename\",\n    y_col=\"species\",\n    subset=\"validation\",\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"categorical\",\n    target_size=(64,64))\n\"\"\"\n\n\n# build a CNN model for classification\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding='same',\n                 input_shape=(64,64,3)))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\nmodel.add(Conv2D(128, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(128, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_class, activation='softmax'))\n\nadam = Adam(lr=0.0005, decay=1e-6)\nmodel.compile(optimizer=adam, loss=\"categorical_crossentropy\" ,metrics=[\"accuracy\"])\nmodel.summary()\n\n# train the model\nSTEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n#STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n\nmodel.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    #validation_data=valid_generator,\n                    #validation_steps=STEP_SIZE_VALID,\n                    epochs=150)\n#model.evaluate_generator(generator=valid_generator, steps=STEP_SIZE_VALID)\n\n# serialize model to JSON\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n\n# serialize weights to HDF5\nmodel.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")\n \n# later...\n \n# load json and create model\njson_file = open('model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n\n# load weights into new model\nloaded_model.load_weights(\"model.h5\")\nprint(\"Loaded model from disk\")\n\n\n\n# Reference: https://medium.com/gradientcrescent/urban-sound-classification-using-convolutional-neural-networks-with-keras-theory-and-486e92785df4","execution_count":8,"outputs":[{"output_type":"stream","text":"mkdir: cannot create directory ‘/kaggle/working/train’: File exists\r\n","name":"stdout"},{"output_type":"stream","text":" 61%|██████    | 1224/2000 [23:56<14:50,  1.15s/it] ","name":"stderr"},{"output_type":"stream","text":"Error encountered while parsing file:  ../input/birdsong-recognition/train_audio/lotduc/XC195038.mp3\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 2000/2000 [38:46<00:00,  1.16s/it]\n","name":"stderr"},{"output_type":"stream","text":"Found 1999 validated image filenames belonging to 27 classes.\n","name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"name 'num_classes' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-fa95068387c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0madam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'num_classes' is not defined"]}]}],"metadata":{"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}